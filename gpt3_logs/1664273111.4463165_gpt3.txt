Summarize the following paper for literature review.


PAPER:
 Image /Q_uality Assessment Guided Deep Neural Networks Training Zhuo Chen Interdisciplinary Graduate School, Nanyang Technological University ZCHEN036@e.ntu.edu.sgWeisi Lin School of Computer Science and Engineering, Nanyang Technological UniversityShiqi Wang Department of Computer Science, City University of Hong Kong Long Xu Key Laboratory of Solar Activity, National Astronomical Observatories, Chinese Academy of SciencesLeida Li School of Information and Control Engineering, China University of Mining and Technology ABSTRACT For many computer vision problems, the deep neural networks are trained and validated based on the assumption that the input images are pristine (i.e., artifact-free). However, digital images are subject to a wide range of distortions in real application scenarios, while the practical issues regarding image quality in high level visual information understanding have been largely ignored. In this paper, in view of the fact that most widely deployed deep learning models are susceptible to various image distortions, the distorted images are involved for data augmentation in the deep neural network training process to learn a reliable model for practical applications. In particular, an image quality assessment based label smoothing method, which aims at regularizing the label distribution of train- ing images, is further proposed to tune the objective functions in learning the neural network. Experimental results show that the proposed method is eective in dealing with both low and high quality images in the typical image classi/f_ication task. KEYWORDS Deep learning, image quality, label distribution 1 INTRODUCTION Recently, deep neural networks (DNNs) have demonstrated state- of-the-art performance in various computer vision tasks, e.g., face recognition [ 13,15], pedestrian detection [ 9] and pose estimation [17]. In contrast to the handcrafted features such as Scale-Invariant Feature Transform (SIFT) [ 8], deep learning based approaches are able to learn representative features directly from the vast amounts of data. For general nature image classi/f_ication, which is of great interest to DNN models, the AlexNet model [ 5] has achieved 9% better classi/f_ication accuracy than the previous hand-crafted meth- ods in the 2012 ImageNet competition [ 10], which provides a large scale training dataset with 1.2 million images and one thousand categories. Subsequently, inspired by such fantastic progress, DNN models continue to be the undisputed leaders in the competition of ImageNet. In particular, both VGGNet [ 12] and GoogLeNet [ 14] an- nounced promising performance in the ILSVRC 2014 classi/f_ication challenge, which demonstrated that deeper and wider architectures can bring great bene/f_its in learning better representations via large scale datasets. For face recognition, DeepID [ 13] trained on 202,599 face images of 10,177 identities has achieved 96.05% accuracy onLFW, and DeepFace [ 15] developed by Facebook yielded 97.35% accuracy with 4.4 million faces of 4,030 identities data. Moreover, Google [ 11] used over 100 million face samples from 8 million iden- tities to train DNN models, which achieved 99.63% accuracy on LFW. Generally speaking, DNN is a data driven method making it feasible to achieve outstanding performance with the explosion of big data. However, such property gives rise to the fact that the capability of deep models heavily relies on the training samples. In particular, most DNN models were trained and tested based on the assumption that the input image samples are pristine without any distortions injected. As such, they can achieve promising per- formance on high quality samples, but the performance will be seriously degraded when encountering with low quality images. Fig. 1 provides some examples in CIFAR-10 dataset [ 4] and it is shown that DNN model fails in predicting the correct classes when the input images are distorted. A recent work [ 3] evaluated several classical deep models for image classi/f_ication by injecting dierent types of distortion into the test images. The results show that all the evaluated neural networks are susceptible to typical distortions such as blur and noise. For example, more than 20% Top 1 and Top 5 accuracy drop can be observed when the images are distorted by Gaussian blur. In real application scenarios, distortions will be introduced in image acquisition, compression, processing, transmission and repro- duction. Generally speaking, restoration of such distorted images is an ill-posed problem, and even state-of-the-art algorithms cannot eciently remove such artifacts. Therefore, evaluating the visual quality of these distorted images becomes meaningful. In the lit- erature, there are numerous approaches proposed to assess the degradation of visual quality [ 6]. Popular image quality assessment (IQA) algorithms such as SSIM [ 19], FSIM [ 21], GSIM [ 7], VSNR [2], PCQI [ 18], etc., focus on the perception of quality degradation from the perspective of viewing experience. Due to the fact that the distortions can also bring diculties in image understanding, it becomes more and more important to further investigate the applications of these IQA algorithms in the context of computer vision, as computer vision systems aim to automatically achieve the high-level understanding tasks that the human visual system can perform. This naturally inspires us to incorporate the quality measure in the DNN learning process to deal with the visual understandingarXiv:1708.03880v1  [cs.CV]  13 Aug 2017 Zhuo Chen, Weisi Lin, Shiqi Wang, Long Xu, and Leida Li  Pristine  Blur Noise  JPEG    Pristine  Blur Noise  JPEG   air- plane      air-plane   ship   deer   ship   dog     dog   cat   cat   cat  auto- mobile      auto- mobile   air-plane   frog   truck   frog     frog   deer   deer   deer  bird     bird   cat   dog   cat   horse      horse   dog   cat   dog  cat     cat   bird   bird   dog   ship     ship   deer   deer   deer


LITERATURE REVIEW SUMMARY:

==========

This paper explores the idea of using image quality assessment to guide the training of deep neural networks. The authors believe that this will lead to more reliable models that can deal with low quality images, which are often encountered in real-world scenarios. To test this idea, they propose a label smoothing method that takes into account the quality of training images. Experimental results show that the proposed method is effective in dealing with both low and high quality images.