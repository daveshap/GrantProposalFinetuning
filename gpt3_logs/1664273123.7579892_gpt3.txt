Summarize the following paper for literature review.


PAPER:
323264 55;1 pool1 323264 161664 33;2 lrn1 161664 161664 / con/v.alt2 161664 161664 55;1 lrn2 161664 161664 / pool2 161664 8864 33;2 f c1 4096 384 / f c1 384 192 / sof tmax 192 10 / the input of second convolutional layer. Subsequently, the simi- lar process is applied again to produce the input of the following fully connected layers whose activation function is also ReLU. Fi- nally, the softmax layer takes the representation learned by the network to create the /f_inal classi/f_ication results, which characterize the probabilities of the input belonging to each given class. 4.3 Parameter setting The proposed deep architectures are trained with stochastic gradi- ent descent method on a NVIDIA GeForce 980Ti GPU with batch size 100 for 2,000 epochs. All our experiments use the initial learning rate of 0.1 which decays for every 350 epochs with an exponential rate of 0.1. In addition, L2Loss weight decay multiplied by 0.004 is added to the two full-connected layers. Regarding the training data, pristine images and the mixture data with both pristine and distorted images are used for validations. The pristine data are totally from the CIFAR-10 training dataset, and the mixture data are the combination of pristine and distorted images with dierent distortion levels in a /f_ixed ratio. In each training epoch, 60% of the pristine training samples are maintained, 15% of them are with le/v.altel1distortion, another 15% of them are with le/v.altel2distortion, and the rest 10% samples are distorted in le/v.altel3. Speci/f_ically, for the blur distortion, we use the Gaussian kernels with=0:7;1:0;1:2forle/v.altelsfrom 1 to 3 respectively. With respect to the noise artifacts, three levels of white Gaussian noise with variance values /v.alt=0:005 ;0:01;0:02are employed. Regarding to JPEG compression, we compress the images with the JPEG quality factors of 12;8;4corresponding to the distortion le/v.altelsfrom 1 to 3. In particular, the images generated by the selected parameters can severely in/f_luence the inference performance of deep networks, which has also been pointed out in [3]. In summary, /f_ive dierent types of training set are utilized in the experiments: one pristine training set and four sets of mixture data with both pristine and distorted samples. For convenience, the four sets of mixture data are denoted as MIX blur,MIX noise ,MIX /J.altP EG andMIX all3, where MIX blur,MIX noise andMIX /J.altP EG represent the training sets of mixture data with pristine and distorted images Image /Q_uality Assessment Guided Deep Neural Networks Training Table 2: Performance comparisons of the models with dierent training strategies. StrategyRegularization TrainingPristineBlur Noise JPGE Method Set Level 1 Level 2 Level 3 Level 1 Level 2 Level 3 Level 1 Level 2 Level 3 1 Original Pristine 0.794 0.676 0.524 0.436 0.677 0.566 0.392 0.600 0.529 0.391 2 Original MIX blur 0.781 0.777 0.766 0.751 0.735 0.681 0.585 0.669 0.621 0.469 3 IQA-LS MIX blur 0.798 0.782 0.766 0.749 0.749 0.698 0.607 0.681 0.624 0.465 4 Original MIX noise 0.794 0.716 0.606 0.526 0.779 0.773 0.749 0.693 0.640 0.496 5 IQA-LS MIX noise 0.807 0.736 0.612 0.525 0.792 0.776 0.743 0.699 0.642 0.503 6 Original MIX /J.altP EG 0.753 0.728 0.711 0.656 0.720 0.662 0.616 0.710 0.687 0.607 7 IQA-LS MIX /J.altP EG 0.791 0.751 0.704 0.622 0.742 0.667 0.607 0.722 0.693 0.590 8 Original MIX all3 0.767 0.753 0.737 0.721 0.761 0.744 0.725 0.721 0.686 0.599 9 IQA-LS MIX all3 0.790 0.773 0.753 0.738 0.771 0.757 0.731 0.726 0.692 0.585 degraded by one certain type of distortion (blur, noise and JPEG respectively), while MIX all3is the combination of pristine and all the three types of distorted samples. With respect to the testing data, a pristine set and nine distorted sets (with three dierent types and each one has three distortion levels) are generated for evaluating each learned model. Example images with the three types of artifact are also illustrated in Fig. 1. 4.4 Performance comparisons Nine dierent training approaches are implemented to evaluate the performance of the proposed scheme. All these nine approaches share the same architecture, as introduced in the sub-section 4.2, but dierent training strategies. These training strategies are with dierent combinations of data augmentation strategies and label distributions. Here, we will detail these training strategies and analyse their performance in terms of the classi/f_ication accuracy, as illustrated in Table 2. 4.4.1 Training on pristine dataset. Strategy 1 in Table 2 aims to train deep models with the pristine CIFAR-10 training samples without the augmented data. Moreover, the label distribution of each training image is the classical 0-1 distribution. Such training strategy follows the widely adopted benchmark models such as AlexNet and VGG. Therefore, we consider this approach as the baseline. From Table 2, we can see that the model trained with this strategy is sensitive to all the three involved distortions as the classi/f_ication performance decreases dramatically when the distortion level in- creases. For instance, even with the blur le/v.altel1 where the value of Gaussian kernel is moderate, the accuracy drops more than 10%. Similar trends can be observed for noise and JPEG compression artifacts. This is in accordance with the evaluation results in [ 3]. This phenomenon can be explained by the fact that the distortions can heavily remove the texture and edge information in an image, which is important to the DNN models learned with pristine images since such DNN models may always attempt to look for speci/f_ic textures and edges for the classi/f_ication task.4.4.2 Training on mixture dataset. Strategies 2,4,6,8 in Table 2 train DNN models with the mixture data of pristine and distorted images while the label distribution maintains the typical 0-1 distri- bution. Such kind of training approach is a straightforward solution to make the network better adapt


LITERATURE REVIEW SUMMARY:

==========

The paper evaluates different training strategies for deep neural networks in order to improve their performance on distorted images. The authors find that training on a mixture of pristine and distorted images, with the label distribution maintained as a typical 0-1 distribution, is the most effective approach. This training strategy results in better classification performance on all three types of distortions (blur, noise, and JPEG compression) than training on pristine images alone.