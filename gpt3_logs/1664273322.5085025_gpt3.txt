Summarize the following paper for literature review.


PAPER:
95, 042303 (2017). [35] See Supplemental Material at [URL will be in- serted by publisher] for a description of the For- tran 90 and Python 3 codes uploaded to github (https://github.com/DanielAlejandroMartin/Apparently- Similar-Neuronal). [36] D. R. Chialvo, S. A. Cannas, T. S. Grigera, D. A. Martin, and D. Plenz, Sci. Rep. 10, 12145 (2020). [37] E. S. Loscar, E. E. Ferrero, T. S. Grigera, and S. A. Cannas, J. Chem. Phys. 131, 024120 (2009). [38] M. Copelli and P. R. A. Campos, Eur. Phys. J. B 56, 273 (2007). [39] T. S. Mosqueiro and L. P. Maia, Phys. Rev. E 88, 012712 (2013). [40] A.-C. Wu, X.-J. Xu, and Y.-H. Wang, Phys. Rev. E 75, 032901 (2007). [41] V. R. V. Assis and M. Copelli, Phys. Rev. E 77, 011923 (2008). [42] M. Kuperman and G. Abramson, Phys. Rev. Lett. 86 2909 (2001). [43] H. Markram, Nat. Rev. Neurosci. 7, 153 (2006). [44] A. P. Alivisatos, M. Chun, G. M. Church, R. J. Greenspan, M. L. Roukes, and R. Yuste, Neuron 74, 970 (2012). 9 [45] S. M. Sunkin, L. Ng, C. Lau, T. Dolbeare, T. L. Gilbert, C. L. Thompson, M. Hawrylycz, and C. Dang, Nucleic Acids Res. 41, D996 (2012). Here we comment on the implementation of the models used to generate the results in the main text. The respec- tive codes in Fortran 90 and Python 3 can be found on GitHub[1]. VI. IMPLEMENTATION OF THE WATTS-STROGATZ NETWORK In Fortran 90, the code Matrix.f90 is used to generate an undirected Watts-Strogatz network with parameters N,, andhkiwhich is saved as a two columns ascii  le MyMatrix.txt of lengthNhki=2. Each row has two integer numbers, iandj, which denote a symmetric edge between nodes iandj. For Python, the Watts-Strogatz network is generated using the available code from the networkx package. VII. IMPLEMENTATION OF THE GREENBERG & HASTINGS (GH) MODEL A. Fortran 90 code The dynamics of the GH model, given by Eqs. 1 (a)- (c) of the main text, is implemented by the program GH_model.f90 . The main code reads the  le MyMatrix.txt (generated as explained in the previous section), and assigns weights to each connection according to an exponential distribu- tion as explained in the main text. For each value of the control parameter T, it runs the ConstantStep subrou- tine for a given number of steps (typically 50 :000), up- dating synchronously the network state using the Step subroutine. At the end of the ConstantStep subroutine, it computes the order parameter fSand the autocorrela- tion coecient AC(1). At each time step ttheStep sub- routine computes the state of all neurons at time t+ 1, S(t+ 1), fromS(t). For each neuron i: 1. If the neuron iwasquiescent (i.e.,Si(t) = 0), it will become activeSi(t+ 1) = 1 with probability r1. If that does not happen, a loop over all jconnected toiis made. For each active j(i.e.,Sj(t) = 1), the weightWi;jis summed up. If the sum is larger thanT, thenSi(t+ 1) = 1. 2. If the neuron was active , (i.e.,Si(t) = 1), it will become refractory (i.e.,Si(t+ 1) = 2) always. 3. If the neuron was refractory , (i.e.,Si(t) = 2), it will become quiescent (i.e.,Si(t+ 1) = 0) with proba- bilityr2. All neurons are updated synchronously.B. Python 3 code The code GH_model.py in Python 3 follows the same steps and uses the same names for variables as in the For- tran 90 code. The code requires the following packages: numpy ,random andnetworkx . The neural activity as a function of time is saved on  les named actN(N)K(K)PI(100*pi)T(1000*T).txt , where the value of is multiplied by 100 and the value of Tis multiplied by 1000, so that they are represented by integer numbers. For instance, for parameters N= 5000, hki= 10,= 0:6 andT= 0:2 the output  le will be named actN5000K10PI60T200.txt VIII. IMPLEMENTATION OF THE KINOUCHI & COPELLI (KC) MODEL In the following we describe the implementation of the code for the KC model used in the main manuscript. Two possible variations of the model are described later in section IX. The KC code follows the same struc- ture as the GH counterpart, starting by reading the  le MyMatrix.txt but changing a few relevant parts: the Step subroutine is obviously di erent and the program cycles trough values of pinstead ofT. Here we call KCmto the code implementation used for the results described in the main text, which follows Eqs. 2 (a)-(d). The codes are KC_m.f90 andKC_m.py for Fortran 90 and Python 3 respectively. At each time step ttheStep subroutine computes the state of all neurons at time t+ 1,S(t+ 1), from S(t). For each neuron the Step subroutine updates the states as follows: 1. For each active neuron j(i.e.,Sj(t) = 1) a loop over all output connections is made. Each quiescent neuroni(i.e.,Si(t) = 0), will become active with probability pWji, 2. If the neuron jwasquiescent (i.e.,Sj(t) = 0), it will become active (Sj(t+ 1) = 1) with probability r1, 3. If the neuron jwasactive , (i.e.,Sj(t) = 1), it will become refractory (i.e.,Sj(t+ 1) = 2) always. 4. If the neuron jwas refractory , in statem, (i.e., Sj(t) =m > 1), it will become refractory with statem+1 (i.e.,Sj(t+1) =m+1) unlessm=n. In that case, if becomes quiescent (i.e.,Sj(t+ 1) = 0). All neurons are updated simultaneously. Within this implementation, it may happen that, in the same time step more than one active neuron activates the same qui- escent neuron. 10 IX. TWO ALTERNATIVE IMPLEMENTATIONS OF THE KC MODEL. As mentioned in the previous section, we explored some algorithmic alternatives for the implementation of the KC model. We will describe two of them here. A. Backward update implementation What we call the backward implementation (see codes KC_b.f90 andKC_b.py ) is described also by Eqs. 2 (a)- (d) of the main text. The only subtle di erence with KCmis in the activation loop within the Step subrou- tine: now it is performed not over the active neurons but over the quiescent neurons. Therefore in this implemen- tation, the Step subroutine is: 1. If neuron iwasquiescent (i.e.,Si(t) = 0), a loop over all input connections jis made. For each ac- tiveneuronj(i.e.,Sj(t) = 1), an attempt to


LITERATURE REVIEW SUMMARY:

==========

The paper describes the implementation of a model for neuronal activity, called the Greenberg-Hastings (GH) model. The model is implemented in both Fortran 90 and Python 3, and the code is available on GitHub. The model is designed to simulate the activity of neurons in a network, and the results of the simulation are saved in a file. The paper also describes the implementation of a second model, called the Kinouchi-Copelli (KC) model, which is similar to the GH model but with some slight variations. The code for the KC model is also available on GitHub.