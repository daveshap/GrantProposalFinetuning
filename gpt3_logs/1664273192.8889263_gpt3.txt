Summarize the following paper for literature review.


PAPER:
both cases we observe that the neural network has high accuracy, but the accuracy is diminished during the quantization and translation to arithmetic logic. Further, we often see an increase in the size of the resultant logic as measured by the number of basic AIG nodes (a standard approach in logic synthesis). We anticipate that the majority healthcare applications will continue to be implemented as software neural networks for the time being. However, we hope to provide a foundation for understanding how to translate from a neural network representation to a logic representation in a principled way that maintains or adds generalizability and limits logic bloat, which would lead to area and power inefciencies. 2 Background Here, we focus on explaining logic-related methods that we use. Additionally, we provide some basics about Boolean logic in Section 7.1 of the appendix. Besides its written form, a Boolean function can be represented by a directed acyclic graph (DAG) in which each node models a logic gate and each edge models a gate connection. A specic implementation of a Boolean function as a DAG is the so-called And-Inverter-Graph (AIG) , for which both AND- and Inverter-gates are part of a universal gate set. In this context, a tool that we use is ABC [14], which provides powerful transformations, such as redundancy removal that leads to a reduced number of nodes and levels. For instance, when AIG rewriting is performed in ABC, a minimal representation is found among all decompositions of all structural cuts in the AIG, while global logic sharing is captured using a structural hashing table [ 14]. In ABC the gates are also factored such that they only receive two inputs and that the nodes follow a topological order. The area or size of an AIG is given by the number of the nodes in the graph, while the depth or delay is given by the number of nodes on the longest path of the primary inputs and outputs. Alook-up table (LUT) is a table that saves previously calculated results or information in form of array-like entries that are easily accessible. In Boolean logic, an N-bit LUT can encode a Boolean function with Ninputs by storing the corresponding truth table. Thus, in the case of Nbits it has 2N rows, one row for each possible bit-pattern. In digital logic, a LUT is implemented with a multiplexer (MUX) , which has select lines. Those are driven by the inputs to the Boolean function to access the value of the corresponding output that is stored in the array. Unlike multiplexers, other arithmetic circuit pieces exist to fulll the task of adding two Boolean numbers, multiplying them or comparing them against each other. The components to realize such calculations are called adder ,multiplier , andcomparator respectively. A method which we use in this paper, to which it can be referred as 2 LogicNet , is formed by a combination of look-up tables [ 20]. Those LUTS are arranged in successive layers, similar to how it is done in neural networks. But a key difference is that the training process does not involve a backpropagation and instead rather is a memorization process. Each LUT in a layer receives inputs from only a few LUTs in the previous layer, for which the connections are chosen at random. The number of outcome columns of a single LUT depends on the number of different outputs that can be observed for the input patterns. Each entry in a row in the outcome columns counts how many times the pattern is associated with the outcome in the given data set. Hence, LogicNet is a network of concatenated look-up tables with multiple layers and serves the memorization of the information given by the data, but also includes noise. Decision trees are a popular method in machine learning, due to their interpretability [ 21]. They are particularly suitable for classication tasks where the feature space can be separated into distinct bins which can be shown as a tree-structure. When using multiple trees in an ensemble and letting them vote on the classication, this substantially improves the accuracy, which leads to a method known as random forests . The growing of a random forest is usually based on random vectors that govern the growth of each tree in an ensemble [22]. 3 Related Work Machine Learning and Logic: The intersection of machine learning and logic is exploited in [ 23], which showed that circuit-based simulations serve as intrinsic method to detect overtting of a machine learning model. Contrastingly, [ 20] investigated the trade-off between memorization and learning with LogicNet. Other work focused on the relationship of neural networks and Boolean satisability. For instance, [ 24,25] use deep neural networks to learn solving satisability problems as an alternative to SAT-solvers. Contrastingly, [ 26] and [ 27] use deep learning to solve problems related to binary decision diagrams, such as variable ordering or estimation of state complexity. Logic Synthesis and Hardware Implementations: There is a substantial amount of work about implementing already trained neural network architectures on Field Programmable Gate Arrays (FPGAs), such as the frameworks provided in [ 28], which employs a synchronous dataow model of computation, [ 29] which allows real-time control of the backpropagation learning algorithm or [30] where the FPGAs native LUTs are used as inference operators. In a regular setting of neural networks being compiled into hardware [ 3134] the starting point are binarized neural networks [35], which have binarized weights and activations during training and thus, have a different training behaviour than standard neural networks. To the best of our knowledge, there is no work to learn logic gate structures by using quantized neural network activations, and compiling them into AIGs. Advances in Health Care: According to [ 36], the advances of deep learning directly affect the eld of medicine and health care at all three levels: clinicians, health systems, and


LITERATURE REVIEW SUMMARY:

==========

This paper discusses the trade-off between memorization and learning with LogicNet, a network of concatenated look-up tables with multiple layers. The paper also describes how decision trees can be used to improve the accuracy of machine learning models. Finally, the paper describes how advances in deep learning are affecting the field of medicine and health care.