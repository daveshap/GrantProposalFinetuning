Summarize the following paper for literature review.


PAPER:
(4940.06) 279 279.00 (0.00) 50.00 47.46 (2.30) 4 20 Yes 1,304,463 1,303,602.67 (7447.86) 291 291.00 (0.00) 49.83 48.62 (2.10) 3 15 Yes 1,001,257 1,004,375.33 (3438.53) 279 279.00 (0.00) 49.50 47.68 (2.87) 2 10 Yes 624,346 623,826.67 (490.61) 263 263.00 (0.00) 49.01 48.68 (0.34) 2 10 No 130,029 129,939.67 (151.28) 267 267.00 (0.00) 47.68 43.76 (6.78) 3 15 No 193,817 193,409.67 (415.21) 322 322.00 (0.00) 47.02 44.48 (3.08) 4 15 No 220,436 220,086.67 (302.53) 360 360.67 (0.58) 46.69 46.58 (0.10) 4 5 No 113,360 113,360.00 (0.00) 322 322.00 (0.00) 46.03 46.03 (0.00) 4 10 No 152,945 152,994.67 (94.82) 343 343.00 (0.00) 46.03 43.99 (2.85) 2 5 No 106,932 106,931.67 (0.58) 246 246.00 (0.00) 45.70 45.70 (0.00) 3 5 No 110,215 110,223.67 (7.51) 284 284.00 (0.00) 45.53 45.53 (0.00) 3 20 No 258,686 258,588.33 (209.35) 335 337.00 (1.73) 44.04 43.71 (0.33) 2 15 No 168,423 168,925.00 (434.74) 284 284.67 (0.58) 41.89 41.56 (0.29) 3 10 No 141,518 141,471.67 (49.22) 305 305.00 (0.00) 32.45 32.12 (0.44) 22 Table 11: Results of the random forest logic on the "V ACS Model 1" setup for a quantization scheme of 7 total bits and 3 fractional bits . EstimatorsMax. DepthBitwiseAIG Nodes (Top1)AIG Nodes (TopN)AIG Levels (Top1)AIG Levels (TopN)Accuracy (Top-1)Accuracy (Top-N) 2 20 No 95,176 95,725.67 (476.25) 177 177.00 (0.00) 49.80 49.05 (0.65) 4 15 No 130,155 130,099.33 (201.36) 202 202.00 (0.00) 48.98 48.01 (1.02) 4 20 No 176,738 176,796.33 (190.33) 213 213.00 (0.00) 48.30 48.28 (0.04) 3 15 No 100,518 100,195.67 (284.42) 184 184.00 (0.00) 47.89 47.57 (0.39) 3 20 No 136,543 136,395.33 (128.10) 195 195.00 (0.00) 47.62 47.35 (0.25) 2 15 No 73,452 73,568.00 (180.53) 166 166.00 (0.00) 45.65 45.53 (0.11) 3 10 No 47,049 47,014.00 (30.32) 164 164.00 (0.00) 44.90 44.85 (0.04) 4 10 No 58,340 58,378.67 (33.72) 182 182.00 (0.00) 44.76 44.67 (0.08) 2 10 No 36,041 36,040.33 (1.15) 146 146.00 (0.00) 42.31 42.31 (0.00) 2 5 No 13,553 13,553.00 (0.00) 126 126.00 (0.00) 39.46 39.46 (0.00) 3 5 No 15,223 15,223.00 (0.00) 144 144.00 (0.00) 37.01 37.01 (0.00) 4 5 Yes 23,571 23,403.00 (150.12) 146 145.33 (0.58) 36.87 35.44 (2.08) 4 5 No 16,867 16,867.00 (0.00) 162 162.00 (0.00) 36.87 36.87 (0.00) 2 10 Yes 85,388 85,808.00 (370.60) 131 131.67 (0.58) 35.85 33.01 (3.69) 3 15 Yes 122,877 122,798.00 (825.34) 143 143.67 (0.58) 35.03 34.49 (0.62) 3 20 Yes 122,838 122,690.67 (494.74) 144 144.00 (0.00) 34.90 33.11 (1.58) 4 15 Yes 157,212 157,803.67 (515.96) 156 155.67 (0.58) 34.35 32.90 (1.30) 4 10 Yes 159,462 159,159.00 (482.16) 156 155.67 (0.58) 34.15 32.90 (2.16) 2 15 Yes 85,366 85,769.33 (390.68) 132 131.67 (0.58) 34.08 31.65 (2.42) 3 10 Yes 121,734 122,420.67 (608.29) 143 143.67 (0.58) 33.88 32.77 (1.20) 2 5 Yes 16,009 16,001.00 (10.58) 121 121.00 (0.00) 33.81 32.52 (1.13) 3 5 Yes 19,314 19,398.67 (148.38) 133 133.33 (0.58) 33.54 32.88 (1.08) 2 20 Yes 86,544 85,704.33 (727.55) 132 131.67 (0.58) 33.33 32.88 (0.48) 4 20 Yes 160,424 159,288.33 (1134.00) 156 155.67 (0.58) 32.99 32.11 (1.19) Table 12: Results of the random forest logic on the "V ACS Model 1" setup for a quantization scheme of 32 total bits and 16 fractional bits . EstimatorsMax. DepthBitwiseAIG Nodes (Top1)AIG Nodes (TopN)AIG Levels (Top1)AIG Levels (TopN)Accuracy (Top-1)Accuracy (Top-N) 2 10 No 25,4579 254,579.00 (0.00) 354 354.00 (0.00) 38.91 38.91 (0.00) 2 15 Yes 1,148,974 1,147,517.33 (1862.34) 350 349.33 (0.58) 37.76 35.03 (2.36) 4 20 No 583,187 584,068.33 (1286.80) 527 527.00 (0.00) 37.07 36.39 (0.90) 2 5 Yes 322,979 322,672.33 (1095.67) 338 338.00 (0.00) 37.01 33.88 (3.35) 3 10 No 280,859 280,859.00 (0.00) 424 424.00 (0.00) 36.46 36.46 (0.00) 3 15 No 389,633 390,194.67 (486.44) 443 443.00 (0.00) 35.99 35.01 (0.93) 3 20 No 504,479 504,248.33 (332.66) 457 457.00 (0.00) 35.85 35.72 (0.12) 4 20 Yes 2,113,290 2,097,819.33 (13473.24) 373 373.00 (0.00) 35.65 34.38 (1.12) 3 10 Yes 1,618,263 1,624,024.00 (13548.57) 360 361.00 (1.00) 35.37 34.69 (0.60) 2 15 No 334,403 333,872.00 (461.82) 373 373.00 (0.00) 35.37 35.26 (0.10) 2 20 No 419,291 418,916.67 (329.78) 387 387.00 (0.00) 35.10 34.94 (0.14) 3 5 Yes 396,919 397,796.00 (775.26) 350 350.67 (0.58) 34.90 34.38 (0.51) 2 10 Yes 1,147,277 1,147,115.00 (3100.18) 349 348.67 (0.58) 34.56 33.83 (1.20) 4 10 Yes 2,098,903 2,096,926.00 (7638.85) 372 372.67 (0.58) 34.49 33.02 (2.10) 4 10 No 304,540 304,540.00 (0.00) 494 494.00 (0.00) 34.35 34.35 (0.00) 4 5 Yes 474,512 475,300.67 (745.59) 362 362.00 (0.00) 33.88 31.95 (1.71) 2 5 No 198,386 198,386.00 (0.00) 334 334.00 (0.00) 33.81 33.81 (0.00) 4 15 No 437,852 437,785.33 (251.71) 513 513.00 (0.00) 33.81 33.45 (0.38) 3 20 Yes 1,625,366 1,626,514.33 (1068.41) 361 361.00 (0.00) 33.54 33.20 (0.59) 2 20 Yes 1,142,434 1,146,674.67 (4637.03) 349 348.67 (0.58) 33.13 31.59 (1.60) 4 15 Yes 2,104,315 2,101,798.67 (4054.02) 373 373.00 (0.00) 32.59 32.24 (0.35) 3 15 Yes 1,619,272 1,618,992.33 (1080.01) 361 361.00 (0.00) 32.38 30.93 (1.29) 3 5 No 203,821 203,821.00 (0.00) 404 404.00 (0.00) 30.95 30.95 (0.00) 4 5 No 209,776 209,776.00 (0.00) 474 474.00 (0.00) 29.80 29.80 (0.00) 23 Table 13: Results of the random forest logic on the "V ACS Model 2" setup for a quantization scheme of 6 total bits and 4 fractional bits . EstimatorsMax. DepthBitwiseAIG Nodes (Top1)AIG Nodes (TopN)AIG Levels (Top1)AIG Levels (TopN)Accuracy (Top-1)Accuracy (Top-N) 3 5 Yes 83,697 83,982.67 (247.88) 146 146.00 (0.00) 37.69 34.17 (3.06) 4 5 Yes 104,782 104,871.00 (105.82) 158 158.00 (0.00) 35.71 33.79 (1.79) 2 10 No 104,390 104,428.00 (194.80) 153 153.00 (0.00) 35.65 34.49 (1.00) 4 10 Yes 1,043,600 1,039,941.33 (3939.50) 180 180.00 (0.00) 35.31 34.08 (1.06) 2 20 Yes 830,090 831,161.00 (931.26) 194 194.00 (0.00) 35.17 34.31 (0.93) 3 10 Yes 792,146 792,785.67 (656.61) 168 168.00 (0.00) 34.97 33.29 (1.46) 4 10 No 176,146 176,089.33 (152.13) 197 197.00 (0.00) 34.76 34.26 (0.45) 3 20 Yes 1,221,817 1,217,937.67 (5600.56) 207 207.33 (0.58) 34.76 33.31 (1.26) 3 5 No 47,409 47,411.67 (2.31) 155 155.00 (0.00) 34.69 34.65 (0.03) 3 15 Yes


LITERATURE REVIEW SUMMARY:

==========

The paper presents the results of a random forest logic on the "V ACS Model 1" setup for a quantization scheme of 7 total bits and 3 fractional bits. The results show that the accuracy of the Top-1 and Top-N predictions is 49.83% and 48.62%, respectively. The AIG nodes and levels are also presented.