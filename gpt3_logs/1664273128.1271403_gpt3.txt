Summarize the following paper for literature review.


PAPER:
to the distorted images. As shown in Table 2, the results exhibit that training strategy with low quality samples improves the performance on the corre- sponding distorted images. For instance, the classi/f_ication accuracy of Strategy 2 only decays about 1% when the distortion level rises from pristine to level 1. Such decreasing speed is an order of mag- nitude slower than that of the baseline strategy. However, it is noticed that the performance of these strategies on high-quality pristine images cannot approach as high as the baseline method, which can be intuitively observed in Fig. 3 (where the dot lines denotes the baseline model while the blue lines denote the models naively trained on mixture data). As discussed in Section 3, this is due to the fact that 0-1 label distribution teaches the model to be equally con/f_ident about the classi/f_ication results of both high and low quality images. 4.4.3 Training with IQA-based label smoothing. Strategies 3,5,7,9 in Table 2 target at training the model based on the mixture data as well. Moreover, in contrast to the previous strategies, the label dis- tribution is regularized by the proposed IQA-based label smoothing method. As shown in Fig. 3, the performance of models trained with IQA- LS is credibly better than the original ones on relative high quality images (e.g.,pristine, distortion level 1 and 2). Regarding to the performance on strongly distorted images (e.g., distortion level 3), although the models trained with IQA-LS are slightly weaker than those without IQA-LS, the performance drop is marginal and accept- able. Therefore, it is concluded that, comparing to the straightfor- ward way that trains the deep models on mixture data, our proposed IQA-LS technique is not only eective in maintaining the high clas- si/f_ication performance for distorted samples, but also promising in improving the accuracy on high quality test data. Moreover, from Fig. 3(d), it is observed that when training on mixture of samples Zhuo Chen, Weisi Lin, Shiqi Wang, Long Xu, and Leida Li 0.740.750.760.770.780.790.8 Pristine Level 1 Level 2 Level 3Accuracy Distortion Level of BlurStrategy 2 Strategy 3 Strategy 1 (a) 0.740.750.760.770.780.790.80.81 Pristine Level 1 Level 2 Level 3Accuracy Distortion Level of NoiseStrategy 4 Strategy 5 Strategy 1 (b) 0.550.60.650.70.750.8 Pristine Level 1 Level 2 Level 3Accuracy Distortion Level of JPEG CompressionStrategy 6 Strategy 7 Strategy 1 (c) 0.550.60.650.70.750.8 Pristine Level 1 Level 2 Level 3Accuracy Distortion Level of Corresponding ArtifactsS. 8 - blur S. 8 - noise S. 8 - JPEG S. 9 - blur S. 9 - noise S. 9 - JPEG S. 1 - blur S. 1 - noise S. 1 - JPEG (d) Figure 3: Performance comparisions. (a) Performance comparisons of the models trained and tested with the distortion type of blur, which correspond to Strategies 2 and 3; (b) Performance comparisons of the models trained and tested on the distortion type of noise, which correspond to Strategy 4 and 5; (c) Performance comparisons of the models trained and tested on the distortion type of JPEG, which correspond to Strategy 6 and 7; and sub/f_igure (d) Performance comparisons of the models trained on all three types of distorted images, and tested for each distortion type individually (e.g., S. 8 - blur means strategy 8 and the blurred images are used for testing). with multiple types of artifacts rather than a certain type the supe- riority of IQA-LS is more apparent. This can be explained by the reason that the regularized label distribution penalises the false inference based on the quality levels, which provides the DNN models with stronger generalizing ability. 4.4.4 Discussions. Here, we perform an in-depth analysis on the proposed scheme to gain a better understanding on the IQA based label-smoothing technique. Let us focus on a certain type of distortion, i.e. blur. Fig. 4 provides some example images along with the con/f_idence values that indicate the prediction results for the cor- rect class with three strategies, which are the baseline and the two trained on MIX blur. In particular, the con/f_idence values are gener- ated by the corresponding node of the softmax layer. Speci/f_ically, the value close to 0 implies that the model is uncon/f_ident about the prediction, while the value close to 1 corresponds to a high con/f_idence prediction. It can be observed that Strategy 3, which utilizes IQA-based label smoothing technique, can always provide asmooth and moderate variation trend on the con/f_idence values with the increase of the blur level. This is in line with the human per- ception, as blurry images may usually lead to uncertainty in image understanding, thus creating lower con/f_idence values. By contrast, the con/f_idence values of Strategies 1 and 2 are more consistent when the distortion level changes. For some cases, the prediction cannot be robust when the distortion level is extremely high (the images in the third and fourth rows of Fig. 4). Moreover, Strategy 2 may suer from the over-/f_itting problem to the high-level distorted images (images in the /f_irst row of Fig. 4). Therefore, the proposed IQA-based label smoothing technique leads to the model that not only provides fairly good prediction per- formance for both high and low quality images, but also simulates human-like perception from the perspective of uncertainty. More- over, the proposed method may also help to reduce the over-/f_itting problem when severely distorted images are used for training. In the future, more distortion types, IQA methods and deep learning models will be investigated in this framework. Image /Q_uality Assessment Guided Deep Neural Networks Training  Pristine  Blur Lv1  Blur Lv2  Blur Lv3          Strategy 1  0.9776  0.9672  0.8494  0.7141   Strategy 2  0.0087  0.0935  0.1515  0.2495   Strategy 3  0.8089  0.6835  0.5552  0.5531          Strategy 1  0.9999  0.9999  0.9986  0.9881   Strategy 2  1.0000  0.9999  0.9999  0.9999   Strategy 3  0.9881  0.8046


LITERATURE REVIEW SUMMARY:

==========

The paper explores the use of image quality assessment (IQA) to improve the performance of deep neural networks (DNNs) when training with distorted images. The paper proposes a method of IQA-based label smoothing to regularize the label distribution and improve the performance of the DNNs. The method is evaluated on three types of distortions: blur, noise, and JPEG compression, and results show that the proposed method outperforms the baseline method on all three types of distortions. The paper also shows that the proposed method is effective in reducing the overfitting problem when training with severely distorted images.