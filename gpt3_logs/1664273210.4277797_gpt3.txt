Summarize the following paper for literature review.


PAPER:
f1;2;3g. Analogously, for random forest, combinations of the following hyper-parameters were used: maximal tree depth: f5;10;15;20g;number of estimators: f2;3;4g;bitwise training:fY es; Nog. Note that the "bitwise training"-parameter means that we introduced the option to train the random forests bit by bit on the quantized activations or on the full bit-string. Besides the training process itself, this also impacts the logic creation. We provide more details about this in the appendix. 5.6 Results Table 2 shows the results of the top-1 model of each conguration. It can be observed that our approach based on random forests outperforms the arithmetic circuits not only in 6 of 8 cases in terms of accuracy, but also most of the times in logic complexity. We also note that the LogicNet approach improves over the arithmetic circuit in some cases, but on the V ACS datasets it seems to degrade essentially to random guessing. Therefore it seems to have more drastic failure modes. Curiously, there is one case in which the neural network accuracy of 63.20% is exactly preserved in the V ACS cohort case by the arithmetic circuit. Since the V ACS cohort is relatively small in terms of the number of features for each data point, it may be possible that an arithmetic circuit learns the full function accurately. However, we expect such cases to be rare. In Section 7.5 of the appendix we additionally provide an example of an interpretable report that can be derived from the logic for the purpose of system verication. There, we also deliver some run-times of MiniSAT [ 15] to proof that such a verication process is possible in a feasible amount of time. For a large logic setting of 912,589 AIG nodes MiniSAT allocates a maximum of approximately six hours. In most cases the run-time is in a magnitude of a few minutes to hours. Table 2: Results of the top-1 models for each technique of logic creation, using the neural networks and data use-cases from Table 1 and two quantization schemes each. Our methods values in each performance measure category are marked in bold if they outperform the ones of the arithmetic circuit. Note that a value of zero for the AIG nodes and levels means that the model has learned nothing and that the logic only delivers a constant classication output. Reference KeyReal-Valued Network Acc. (in %)Quant. SchemeArithmetic Circuit LogicNet NNET to Random Forest AIG NodesAIG LevelsAcc. (in %)AIG NodesAIG LevelsAcc. (in %)AIG NodesAIG LevelsAcc. (in %) GIB Model 1 83.28(7, 3) 14,314 231 70.36 2,508 106 66.56 50,684 245 83.28 (18, 10) 123,389 451 83.28 25,536 198 65.56 114,011 357 77,65 GIB Model 2 85.93(6, 4) 38,414 240 52.48 13,501 131 64.40 425,617 213 56.29 (12, 8) 150,427 338 45.20 41,867 165 50.50 214,009 300 59.27 V ACS Model 1 63.20(7, 3) 17,807 183 35.51 7,473 89 33.40 95,176 117 49.80 (32, 16) 338,757 549 63.20 186,572 274 33.40 254,579 354 38.91 V ACS Model 2 75.58(6, 4) 106,572 353 34.97 0 0 33.33 83,697 146 37.69 (32, 16) 2,173,117 726 34.97 389,577 264 33.47 2,097,694 373 39.39 We note that AIGs themselves are minimized for logic redundancy by using a hash table to look up small patches of logic [ 42]. However, though these operations are applied to all three models to derive the nal AIG, they do not compensate accuracy and reach the same node or AIG level count. We believe that this is because the random forest models begin with a better global logic architecture, which local optimizations offered by AIGs can not correct. Based on our results here, we recommend the usage of the derived methods as follows: Begin with small real-valued neural networks and small quantization schemes, to derive an arithmetic circuit. When the arithmetic circuit performs poorly, our pipeline helps to increase the chance of nding a well-generalizing logic circuit that is smaller in terms of size and area and better in terms of accuracy. When the arithmetic circuit already performs well, thus forms a strong baseline, the logic learning pipeline can help nding a less bloated logic that achieves similar results. 8 6 Conclusion Here, we presented a novel framework for translating trained neural networks rst into random forests and then into logic gate representations. The motivation was to combine the learnability of neural networks with the veriability and implementability of logic. We noted that, in general, translation of a neural network into arithmetic logic incurs a loss of accuracy. We found that the inclusion of training random forests for each activation before the translation to logic increases accuracy and decreases hardware complexity. We showed that the intermediate optimizations are a form of dependency elimination on the logic and thus, allow for exploiting logic smoothness, and improves generalization. Thus, we provide evidence that particular logic operations themselves can generalize to unseen training examples. Future work remains in investigating the properties of our intermediate operations and different quantization schemes. Broader Impact Our work has broad applicability in many elds, and especially health care, where there is an advantage to performing logically veriable decisions. Additionally, with our work we hope to deliver a new motivation for the machine learning community to further explore the intersection of neural networks and logic circuits. We believe that there is a high potential in translating machine learning models to logic circuits for several reasons: 1. Logic is veriable. 2. Logic can be more interpretable. 3.Logic is implementable in hardware. Thus, if logic was learnable, machine learning models could also more easily be run on chips. 4.Logic could in the long-run maybe be seen as an intermediate step of rendering one machine learning model from another. This could lead to totally new concepts when it comes to intersecting multiple domains. Hence, one of the next steps could be to again derive a trainable machine learning model from logic. We


LITERATURE REVIEW SUMMARY:

==========

The paper presents a novel framework for translating trained neural networks into random forests and then into logic gate representations. The motivation is to combine the learnability of neural networks with the verifiability and implementability of logic. The framework is evaluated on several datasets, and the results show that it outperforms the traditional approach of translating neural networks into arithmetic logic in terms of accuracy and hardware complexity.