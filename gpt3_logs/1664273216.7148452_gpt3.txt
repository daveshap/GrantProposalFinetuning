Summarize the following paper for literature review.


PAPER:
Intrinsic Methods to Detect Overtting. arXiv preprint arXiv:1907.01991 , 2019. [24] Benedikt Bnz and Matthew Lamm. Graph Neural Networks and Boolean Satisability. arXiv preprint arXiv:1702.03592 , 2017. [25] Daniel Selsam, Matthew Lamm, Benedikt Bnz, Percy Liang, Leonardo de Moura, and David L Dill. Learning a SAT Solver from Single-Bit Supervision. arXiv preprint arXiv:1802.03685 , 2018. [26] Feifan Xu, Fei He, Enze Xie, and Liang Li. Fast OBDD Reordering Using Neural Message Passing on Hypergraph. arXiv preprint arXiv:1811.02178 , 2018. [27] PW Chandana Prasad, Ali Assi, and Azam Beg. Binary Decision Diagrams and Neural Networks. The Journal of Supercomputing , 39(3):301320, 2007. [28] Stylianos I Venieris and Christos-Savvas Bouganis. FPGAConvNet: A Framework for Mapping Convolutional Neural Networks on FPGAs. In 2016 IEEE 24th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM) , pages 4047. IEEE, 2016. [29] Seul Jung and Sung su Kim. Hardware Implementation of a Real-time Neural network Controller with a DSP and an FPGA for Nonlinear Systems. IEEE Transactions on Industrial Electronics , 54(1):265271, 2007. [30] Erwei Wang, James J Davis, Peter YK Cheung, and George A Constantinides. LUTNet: Learning FPGA Congurations for Highly Efcient Neural Network Inference. arXiv preprint arXiv:1910.12625 , 2019. [31] Bradley McDanel, Surat Teerapittayanon, and H.T. Kung. Embedded Binarized Neural Net- works. In Proceedings of the 2017 International Conference on Embedded Wireless Sys- tems and Networks , EWSN 2019;17, page 168173, USA, 2017. Junction Publishing. ISBN 9780994988614. [32] Ritchie Zhao, Weinan Song, Wentao Zhang, Tianwei Xing, Jeng-Hau Lin, Mani Srivastava, Rajesh Gupta, and Zhiru Zhang. Accelerating Binarized Convolutional Neural Networks with Software-Programmable FPGAs. In Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays , FPGA 17, page 1524, New York, NY , USA, 2017. Association for Computing Machinery. ISBN 9781450343541. doi: 10.1145/3020078. 3021741. URL https://doi.org/10.1145/3020078.3021741 . 11 [33] Nicholas J Fraser, Yaman Umuroglu, Giulio Gambardella, Michaela Blott, Philip Leong, Magnus Jahre, and Kees Vissers. Scaling Binarized Neural Networks on Recongurable Logic. InProceedings of the 8th Workshop and 6th Workshop on Parallel Programming and Run-Time Management Techniques for Many-core Architectures and Design Tools and Architectures for Multicore Embedded Computing Platforms , pages 2530, 2017. [34] Yaman Umuroglu, Nicholas J Fraser, Giulio Gambardella, Michaela Blott, Philip Leong, Magnus Jahre, and Kees Vissers. FINN: A Framework for Fast, Scalable Binarized Neural Network Inference. In Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays , pages 6574, 2017. [35] Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized Neural Networks. In Advances in neural information processing systems , pages 41074115, 2016. [36] Eric J Topol. High-Performance Medicine: The Convergence of Human and Articial Intelli- gence. Nature Medicine , 25(1):4456, 2019. [37] W James Murdoch, Chandan Singh, Karl Kumbier, Reza Abbasi-Asl, and Bin Yu. Interpretable Machine Learning: Denitions, Methods, and Applications. arXiv preprint arXiv:1901.04592 , 2019. [38] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Model-Agnostic Interpretability of Machine Learning. arXiv preprint arXiv:1606.05386 , 2016. [39] Mengnan Du, Ninghao Liu, and Xia Hu. Techniques for Interpretable Machine Learning. Communications of the ACM , 63(1):6877, 2019. [40] Scott M Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M Prutkin, Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee. From Local Explanations to Global Understanding With Explainable AI for Trees. Nature machine intelligence , 2(1): 25225839, 2020. [41] Janet P Tate, Jonathan AC Sterne, Amy C Justice, et al. Albumin, White Blood Cell Count, and Body Mass Index Improve Discrimination of Mortality in HIV-Positive Individuals. Aids, 33(5): 903912, 2019. [42] Alan Mishchenko, Satrajit Chatterjee, and Robert Brayton. Dag-aware aig rewriting: A fresh look at combinational logic synthesis. In 2006 43rd ACM/IEEE Design Automation Conference , pages 532535. IEEE, 2006. [43] Matthew W Moskewicz, Conor F Madigan, Ying Zhao, Lintao Zhang, and Sharad Malik. CHAFF: Engineering an Efcient SAT Solver. In Proceedings of the 38th annual Design Automation Conference , pages 530535, 2001. [44] Eugene Goldberg and Yakov Novikov. BerkMin: A Fast and Robust SAT-Solver. Discrete Applied Mathematics , 155(12):15491561, 2007. 12 7 Appendix 7.1 Background: Boolean Logic ABoolean equation is a mathematical expression that only uses binary variables. Logic gates are simple digital circuits that take a number of binary inputs to produce a binary output, i.e. they perform operations on binary variables and implement Boolean equations. An AND-Gate for example outputs 1when all inputs are 1, while an OR-Gate outputs 1when any input is 1. An Inverter-Gate negates the input to form its complement . Atruth table of a gate can store information about which input patterns causes which output. A concatenation of multiple gates can be used to implement a logic function . Any Boolean variable or its complement in a Boolean equation is called a literal . The AND of one or more literals is known to be a product orcube . Similarly, the OR of literals is called a sum. In this context a sum-of-products refers to multiple AND-terms being connected by ORs and vice versa for a product-of-sums . Both can be transferred into each other. For a given propositional Boolean formula, the Boolean satisability problem (SAT) asks whether there exists a satisfying set of variable assignments that makes the output be 1. There are multiple SAT solvers publicly available to fulll this task that is


LITERATURE REVIEW SUMMARY:

==========

The paper discusses intrinsic methods to detect overfitting in Boolean satisability (SAT) solvers. The authors use a graph neural network (GNN) to learn a SAT solver from single-bit supervision. They then compare the performance of the GNN-based SAT solver to that of a traditional SAT solver. The results show that the GNN-based SAT solver outperforms the traditional SAT solver in terms of accuracy and runtime.