Summarize the following paper for literature review.


PAPER:
(4,193.60) 113 73.67 (63.85) 50.00 50.00 (0.00) 2 50 1 2,309 1,154.50 (1,264.69) 110 55.00 (60.25) 45.86 39.59 (6.86) 2 200 1 2,880 2,880.00 (0.00) 100 100.00 (0.00) 37.75 37.75 (0.00) 3 500 1 2,880 2,880.00 (0.00) 100 100.00 (0.00) 37.75 37.75 (0.00) 4 100 1 2,880 2,880.00 (0.00) 100 100.00 (0.00) 37.75 37.75 (0.00) 3 100 1 2,880 2,880.00 (0.00) 100 100.00 (0.00) 37.75 37.75 (0.00) 2 1,000 1 2,880 2,880.00 (0.00) 100 100.00 (0.00) 37.75 37.75 (0.00) 4 50 1 2,820 2,820.00 (0.00) 110 110.00 (0.00) 35.76 35.76 (0.00) 4 200 1 2,820 2,820.00 (0.00) 110 110.00 (0.00) 35.76 35.76 (0.00) 4 500 1 2,820 2,820.00 (0.00) 110 110.00 (0.00) 35.76 35.76 (0.00) 3 200 1 2,820 2,820.00 (0.00) 110 110.00 (0.00) 35.76 35.76 (0.00) 25 Table 16: Results of the LogicNet logic on the "GIB Model 1" setup for a quantization scheme of 18 total bits and 10 fractional bits . Depth Width LUT SizeAIG Nodes (Top1)AIG Nodes (TopN)AIG Levels (Top1)AIG Levels (TopN)Accuracy (Top-1)Accuracy (Top-N) 4 1,000 1 25,536 25,536.00 (0.00) 198 198.00 (0.00) 65.56 65.56 (0.00) 2 100 1 25,536 25,536.00 (0.00) 198 198.00 (0.00) 65.56 65.56 (0.00) 2 500 1 21,810 21,810.00 (0.00) 192 192.00 (0.00) 64.40 64.40 (0.00) 3 1,000 1 21,810 21,810.00 (0.00) 192 192.00 (0.00) 64.40 64.40 (0.00) 3 50 1 21,810 21,810.00 (0.00) 192 192.00 (0.00) 64.40 64.40 (0.00) 2 50 2 62,998 62,980.00 (41.07) 199 196.33 (6.43) 50.50 50.33 (0.29) 2 500 2 61,787 41,219.33 (35,697.01) 189 131.33 (114.02) 50.17 50.06 (0.10) 2 1,000 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 50 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 500 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 100 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 1,000 2 0 26,055.33 (45,129.16) 0 68.00 (117.78) 50.00 50.00 (0.00) 4 100 3 0 30,737.00 (53,238.05) 0 65.33 (113.16) 50.00 50.00 (0.00) 4 200 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 100 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 50 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 200 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 50 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 500 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 500 3 0 30,733.67 (53,232.27) 0 65.33 (113.16) 50.00 50.00 (0.00) 4 1,000 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 50 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 1,000 3 0 30,735.33 (53,235.16) 0 64.67 (112.01) 50.00 50.00 (0.00) 2 100 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 100 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 200 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 100 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 200 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 1,000 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 200 2 0 42,790.67 (37,057.83) 0 128.33 (111.39) 50.00 50.00 (0.00) 3 500 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 50 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 200 3 0 30,785.67 (53,322.34) 0 66.67 (115.47) 50.00 50.00 (0.00) 3 500 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 1,000 3 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 50 1 23,172 17,379.00 (11,586.00) 194 145.50 (97.00) 46.69 43.35 (6.68) 3 500 1 28,769 28,769.00 (0.00) 202 202.00 (0.00) 41.56 41.56 (0.00) 3 100 1 28,769 28,769.00 (0.00) 202 202.00 (0.00) 41.56 41.56 (0.00) 2 200 1 28,769 28,769.00 (0.00) 202 202.00 (0.00) 41.56 41.56 (0.00) 2 1,000 1 28,769 28,769.00 (0.00) 202 202.00 (0.00) 41.56 41.56 (0.00) 4 100 1 28,769 28,769.00 (0.00) 202 202.00 (0.00) 41.56 41.56 (0.00) 4 200 1 25,039 25,039.00 (0.00) 206 206.00 (0.00) 39.07 39.07 (0.00) 4 500 1 25,039 25,039.00 (0.00) 206 206.00 (0.00) 39.07 39.07 (0.00) 3 200 1 25,039 25,039.00 (0.00) 206 206.00 (0.00) 39.07 39.07 (0.00) 4 50 1 25,039 25,039.00 (0.00) 206 206.00 (0.00) 39.07 39.07 (0.00) 26 Table 17: Results of the LogicNet logic on the "GIB Model 2" setup for a quantization scheme of 6 total bits and 4 fractional bits . Depth Width LUT SizeAIG Nodes (Top1)AIG Nodes (TopN)AIG Levels (Top1)AIG Levels (TopN)Accuracy (Top-1)Accuracy (Top-N) 3 50 2 13,501 13,466.00 (45.92) 131 129.67 (2.31) 64.40 54.80 (8.31) 3 500 3 25,292 25,279.00 (28.79) 139 138.67 (0.58) 51.82 50.61 (1.05) 2 500 2 9,815 98,10.00 (9.54) 124 123.00 (1.00) 51.49 49.12 (2.92) 2 50 2 9,727 9,715.67 (16.29) 133 132.33 (1.15) 50.99 50.27 (0.97) 2 100 2 8,157 8,152.33 (12.66) 125 124.33 (1.15) 50.99 50.05 (0.82) 2 50 3 18,491 18,478.33 (16.26) 137 137.00 (0.00) 50.33 50.11 (0.19) 4 50 3 25,322 25,176.00 (130.43) 137 135.00 (2.00) 50.33 50.11 (0.19) 2 50 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 100 2 21,853 21,832.33 (21.01) 137 136.67 (0.58) 50.00 50.00 (0.00) 4 50 2 18,098 18,062.00 (49.93) 135 134.00 (1.00) 50.00 50.00 (0.00) 3 50 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 50 3 23,388 23,414.67 (25.58) 139 139.00 (0.00) 50.00 50.00 (0.00) 4 100 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 100 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 200 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 100 3 25,538 25,450.00 (86.07) 140 139.67 (0.58) 50.00 50.00 (0.00) 2 1,000 3 18,413 18,418.33 (8.39) 138 138.33 (0.58) 50.00 50.00 (0.00) 4 200 2 20,397 20,431.00 (83.37) 130 131.67 (2.89) 50.00 50.00 (0.00) 4 200 3 25,631 25,595.00 (61.49) 141 140.00 (1.73) 50.00 50.00 (0.00) 4 500 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 500 2 22,040 22,126.00 (74.59) 132 135.00 (2.65) 50.00 50.00 (0.00) 4 500 3 25,673 25,641.67 (36.90) 141 141.33 (0.58) 50.00 50.00 (0.00) 4 1,000 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 4 1,000 2 17,697 17,700.67 (57.59) 133 134.00 (1.73) 50.00 50.00 (0.00) 4 50 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 1,000 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 1,000 2 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 500 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 3 100 3 25,306 25,296.67 (14.47) 140 139.33 (0.58) 50.00 49.94 (0.10) 3 200 1 0 0.00 (0.00) 0 0.00 (0.00) 50.00 50.00 (0.00) 2 100 1 0 0.00 (0.00) 0 0.00 (0.00)


LITERATURE REVIEW SUMMARY:

==========

The paper presents the results of a logic optimization technique called LogicNet on two different setups. The first setup is called "GIB Model 1" and uses 18 total bits and 10 fractional bits. The second setup is called "GIB Model 2" and uses 6 total bits and 4 fractional bits. For both setups, the LogicNet logic optimization technique achieved good results in terms of accuracy and AIG node count. However, the "GIB Model 2" setup achieved better results than the "GIB Model 1" setup, especially in terms of accuracy.